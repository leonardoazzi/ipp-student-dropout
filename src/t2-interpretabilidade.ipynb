{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretabilidade e explicabilidade\n",
    "\n",
    "Os alunos deverão explorar algum método de interpretação de modelos e/ou modelos naturalmente interpretáveis (por exemplo, árvores de decisão), a fim de compreender ou extrair hipóteses sobre quais atributos são aparentemente mais relevantes para a tarefa de predição e/ou como eles impactam na decisão do modelo. Sugere-se que se faça esta investigação apenas para um modelo, a ser escolhido com base no melhor desempenho preditivo em dados de teste (isto é, o melhor modelo conforme análise do grupo). Os grupos deverão incluir no relatório informações obtidas desta análise, como gráficos, tabelas, etc, e discutir a respeito das relações encontradas na análise que mais chamaram a atenção, seja pela pertinência da associação ou por ser um resultado inesperado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas plotly matplotlib seaborn scikit-learn shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulo para leitura e manipulação dos dados\n",
    "import pandas as pd\n",
    "\n",
    "# Módulo para manipulação de arrays e matrizes\n",
    "import numpy as np\n",
    "\n",
    "# Módulos para visualização de dados e plotagem de gráficos\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Módulos específicos da sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Módulo para balanceamento de classes\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/calculate-feature-importance-with-python/\n",
    "\n",
    "You need to be using this version of scikit-learn or higher.\n",
    "0.22.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check scikit-learn version\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carregamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset pré-processado no notebook [t1-spot-checking.ipynb](./t1-spot-checking.ipynb)\n",
    "\n",
    "---\n",
    "Dataset obtido em https://www.kaggle.com/datasets/thedevastator/higher-education-predictors-of-student-retention/data\n",
    "\n",
    "Original: https://zenodo.org/records/5777340#.Y7FJotJBwUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/clean-dataset.csv\")\n",
    "X = data.drop('Target', axis=1)\n",
    "y = data['Target']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Interpretabilidade intrínseca\n",
    "\n",
    "**Interpretabilidade:** a capacidade de explicar ou apresentar em termos compreensíveis para um ser humano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importância de atributos intríseca\n",
    "\n",
    "- Método de obtenção da importância por coeficientes e árvores variam com o algortimo e viés indutivo de cada modelo\n",
    "  - Logistic Regression/DecisionTree/RandomForest/XGBoost: https://machinelearningmastery.com/calculate-feature-importance-with-python/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXEMPLO: coeficientes da regressao logistica\n",
    "\n",
    "# # logistic regression for feature importance\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from matplotlib import pyplot\n",
    "# # define dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# # define the model\n",
    "# model = LogisticRegression()\n",
    "# # fit the model\n",
    "# model.fit(X, y)\n",
    "# # get importance\n",
    "# importance = model.coef_[0]\n",
    "# # summarize feature importance\n",
    "# for i,v in enumerate(importance):\n",
    "# \tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# # plot feature importance\n",
    "# pyplot.bar([x for x in range(len(importance))], importance)\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Interpretabilidade extrínseca\n",
    "\n",
    "**Explicabilidade:** coleção de artefatos visuais e/ou interativos que fornecem ao usuário uma descrição suﬁciente do comportamento de\n",
    "um modelo para executar com precisão tarefas como avaliação, conﬁança, previsão ou melhoria de um modelo.\n",
    "\n",
    "**Explainable Machine learning:** análises post-hoc e técnicas usadas para entender os mecanismos para tomada de decisão ou as previsões realizadas pelo modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmos selecionados para treinamento\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "abc = AdaBoostClassifier(n_estimators=50,learning_rate=1, random_state=0, algorithm='SAMME')\n",
    "svmachine = svm.SVC(kernel='linear',probability=True)\n",
    "\n",
    "algo_dict = {'Logistic Regression': lr, 'AdaBoost': abc, 'SVM': svmachine}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(model):\n",
    "    steps = list()\n",
    "\n",
    "    steps.append(('Feature Selection', SelectKBest(k=10)))\n",
    "    steps.append(('Normalização', StandardScaler()))\n",
    "    steps.append(('Balanceamento da classe minoritária', SMOTE(sampling_strategy='minority')))\n",
    "    steps.append(('Modelo', model))\n",
    "\n",
    "    # Cria a pipeline\n",
    "    pipe = Pipeline(steps=steps)\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importância de Atributos\n",
    "\n",
    "- Método de importância de atributos com **testes de permutação é model agnostic**\n",
    "  - https://machinelearningmastery.com/calculate-feature-importance-with-python/\n",
    "  - https://scikit-learn.org/stable/modules/permutation_importance.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. **Consider running the example a few times and compare the average outcome.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questões\n",
    "- Devemos usar pipeline?\n",
    "  - https://stackoverflow.com/questions/62106204/permutation-importance-using-a-pipeline-in-scikit-learn\n",
    "- Como importar os hiperparâmetros otimizados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_indices = {column: index for index, column in enumerate(data.columns)}\n",
    "print(column_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, algorithm in algo_dict.items():\n",
    "\tprint('Importância de atributos para:', name)\n",
    "\n",
    "\tpipeline = make_pipeline(algorithm)\n",
    "\tpipeline.fit(X, y)\n",
    "\n",
    "\t# perform permutation importance\n",
    "\tresults = permutation_importance(pipeline, X, y, scoring='f1')\n",
    "\timportance = results.importances_mean\n",
    "\n",
    "\t# summarize feature importance\n",
    "\tfor i,v in enumerate(importance):\n",
    "\t\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "\t# plot feature importance\n",
    "\tplt.title(f'Importância de atributos para {name}')\n",
    "\tax = plt.barh([x for x in range(len(importance))], importance)\n",
    "\n",
    "\t# Show the major grid and style it slightly.\n",
    "\tplt.grid(which='major', color='#DDDDDD', linewidth=0.8)\n",
    "\t# Show the minor grid as well. Style it in very light gray as a thin,\n",
    "\t# dotted line.\n",
    "\tplt.grid(which='minor', color='#EEEEEE', linestyle=':', linewidth=0.5)\n",
    "\t\n",
    "\t# Fixa o eixo x do gráfico\n",
    "\tplt.xlim(-0.05, max(importance) + 0.1)\n",
    "\tplt.yticks(ticks=range(len(importance)), labels=[column for column in list(column_indices.keys())[:len(importance)]], rotation=0)\n",
    "\t\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP\n",
    "\n",
    "https://github.com/shap/shap\n",
    "\n",
    "\n",
    "Usando o KernelExplainer, por ser mais agnóstico a modelos, pois o pacote não suporta o AdaBoost diretamente. https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/model_agnostic/Simple%20Kernel%20SHAP.html#Using-KernelExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline with AdaBoost model\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Transform the data using the pipeline's feature selection and scaling steps\n",
    "X_transformed = pipeline.named_steps['Normalização'].transform(pipeline.named_steps['Feature Selection'].transform(X))\n",
    "\n",
    "# Use SHAP to explain the model's predictions\n",
    "explainer = shap.KernelExplainer(pipeline.named_steps['Modelo'].predict, X_transformed)\n",
    "shap_values = explainer.shap_values(X_transformed)\n",
    "\n",
    "# Plot the SHAP values\n",
    "shap.summary_plot(shap_values, X_transformed)\n",
    "\n",
    "# visualize the first prediction's explanation\n",
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demora bastante para usar o KernelExplainer do SHAP\n",
    "\n",
    "https://github.com/ModelOriented/DALEX/issues/366"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDP\n",
    "https://scikit-learn.org/stable/modules/partial_dependence.html\n",
    "\n",
    "IDP: unlike a PDP, which shows the average effect of the input feature, an ICE plot visualizes the dependence of the prediction on a feature for each sample separately with one line per sample. Due to the limits of human perception, only one input feature of interest is supported for ICE plots. While the PDPs are good at showing the average effect of the target features, they can obscure a heterogeneous relationship created by interactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "abc = AdaBoostClassifier(n_estimators=50,learning_rate=1, random_state=0, algorithm='SAMME')\n",
    "pipeline = make_pipeline(abc)\n",
    "model = pipeline.fit(X, y)\n",
    "\n",
    "# One-way Partial Dependence Plot\n",
    "# ==================================\n",
    "features = list(range(20)) # Índices dos atributos que serão plotados\n",
    "\n",
    "PartialDependenceDisplay.from_estimator(model, X, features, n_cols=3)\n",
    "plt.gcf().set_size_inches(15, 30)\n",
    "\n",
    "PartialDependenceDisplay.from_estimator(model, X, features, n_cols=3, kind='both')\n",
    "plt.gcf().set_size_inches(15, 30)\n",
    "\n",
    "# Two-way Partial Dependence Plot\n",
    "# ==================================\n",
    "\n",
    "# Grade 2nd sem vs. Scholarship holder\n",
    "features = [(13,15)]\n",
    "PartialDependenceDisplay.from_estimator(model, X, features)\n",
    "\n",
    "# Tuition Fees Up to Date vs. Grade 2nd sem\n",
    "features = [(11,15)]\n",
    "PartialDependenceDisplay.from_estimator(model, X, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
