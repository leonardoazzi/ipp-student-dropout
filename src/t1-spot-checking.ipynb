{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPMR0Ks4KQFC"
   },
   "source": [
    "# 1. Introdução\n",
    "O notebook abaixo apresenta e implementa o spot-checking de modelos preditivos supervisionados, desenvolvido para primeiro trabalho da disciplina Aprendizado de Máquina da Universidade Federal do Rio Grande do Sul (2024/2).\n",
    "\n",
    "Neste trabalho, buscamos analisar a relação de diversos fatores, como gênero e notas do primeiro semestre, com a taxa de desistência de alunos. No modelo abaixo usamos o dataset carregado nesse notebook, analisamos quais os fatores que de fato influenciam na desistência dos alunos e possibilitamos que inputs personalizados sejam adicionados ao modelo para que seja calculado a probabilidade de um aluno desistir do curso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas plotly matplotlib seaborn scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCKBmgs0ZCVI"
   },
   "outputs": [],
   "source": [
    "# Módulo para leitura e manipulação dos dados\n",
    "import pandas as pd\n",
    "\n",
    "# Módulo para manipulação de arrays e matrizes\n",
    "import numpy as np\n",
    "\n",
    "# Módulos para visualização de dados e plotagem de gráficos\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Módulos específicos da sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "# Biblioteca com algoritmos específicos de machine learning\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Módulo para balanceamento de classes\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kd5SN9ttZ5a3"
   },
   "source": [
    "# 1. Coleta de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset de https://www.kaggle.com/datasets/thedevastator/higher-education-predictors-of-student-retention/data\n",
    "\n",
    "Original: https://zenodo.org/records/5777340#.Y7FJotJBwUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./data/student-dropout.zip'):\n",
    "    !curl -L -o ./data/student-dropout.zip 'https://www.kaggle.com/api/v1/datasets/download/thedevastator/higher-education-predictors-of-student-retention'\n",
    "    !unzip ./data/student-dropout.zip -d ./data\n",
    "else:\n",
    "    print(\"File already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoclZYm6ZTfq",
    "outputId": "bcd659d5-5ee6-45c2-be15-6c7a37ed0226"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Análise Exploratória dos Dados\n",
    "\n",
    "O objetivo é entender melhor e sumarizar as características dos dados, analisando quantidade e tipos de atributos, verificando distribuição do atributo alvo, identificando padrões e anomalias, removendo atributos que pareçam irrelevantes ou problemáticos, etc. Utilize gráficos e sumarizações estatísticas para a EDA. Verifique potenciais problemas nos dados, como por exemplo, a necessidade de normalizar os atributos, balancear classes, ou remover instâncias ou atributos por inconsistências nos dados.\n",
    "\n",
    "Objetivo: compreender como as variáveis do dataset se relacionam com a probabilidade de desistência da universidade.\n",
    "\n",
    "- P1. Qual a quantidade e tipos de atributos? Existem inconsistências?\n",
    "  - Quais são os atributos disponíveis? Dentre eles, quais são os categóricos, e quais são os numéricos?\n",
    "  - Existem inconsistências nos atributos? (Atributos vazios, potenciais erros, etc)\n",
    "  - Existem atributos que necessitam ser removidos ou transformados?\n",
    "- P2. Qual a distribuição do atributo alvo?\n",
    "  - Quais são as classes alvo? Qual a distribuição entre as classes? Está balanceada ou desbalanceada?\n",
    "- P3. Quais os padrões e anomalias dos atributos individuais?\n",
    "  - Quais as relações entre as variávies numéricas e categóricas?\n",
    "- P4. Quais os padrões e anomalias entre todos os atributos?\n",
    "  - Qual o range dos atributos numéricos? Eles necessitam ser normalizados?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P1. Qual a quantidade e tipos de atributos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quantidade de atributos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info(verbose = False, memory_usage = False, show_counts = True) # mostra o tipo e a quantidade de itens não nulos de cada coluna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem 35 atributos, onde um é o atributo alvo ('Target') e os outros 34 são potenciais atributos treináveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tipos de atributos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O atributo alvo é codificado como tipo object, o que significa um ponteiro que aponta para strings. \n",
    "\n",
    "Os 34 atributos potencialmente treináveis estão codificados como atributos numéricos float64 ou int64. Todavia, pela descrição do conjunto de dados, alguns destes parâmetros são categóricos e foram codificados para int64.\n",
    "\n",
    "Isto dificulta a interpreteação dos gráficos e análise entre atributos categóricos e numéricos. Para isto, reconstruímos os atributos categóricos em um novo DataFrame através das informações do data descriptor deste dataset [[1](https://doi.org/10.3390/data7110146)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nosso objetivo de aprendizado é separar os dados entre evasão e permanência, este último que pode ser matriculado (enrolled) ou graduado (graduated), juntamos estas labels através destas traduções/localizações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Target'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Target'] = data['Target'].map({\n",
    "    'Dropout': 'Evasão',\n",
    "    'Enrolled': 'Permanência',\n",
    "    'Graduate': 'Permanência'\n",
    "})\n",
    "\n",
    "data['Target'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em primeiro lugar, separamos manualmente, com base no descritor, o nome dos atributos em duas listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_nominal = ['Application mode', 'Course', 'Previous qualification', 'Nacionality',\n",
    "       \"Mother's qualification\", \"Father's qualification\",\n",
    "       \"Mother's occupation\", \"Father's occupation\"]\n",
    "\n",
    "categorical_binary = ['Marital status', 'Daytime/evening attendance', 'Displaced', 'Gender', 'International', 'Educational special needs',\n",
    "                      'Debtor', 'Tuition fees up to date', 'Scholarship holder', 'Target']\n",
    "\n",
    "categorical_data = categorical_nominal + categorical_binary\n",
    "\n",
    "numerical_data = ['Application order', 'Curricular units 1st sem (credited)',\n",
    "       'Curricular units 1st sem (enrolled)',\n",
    "       'Curricular units 1st sem (evaluations)',\n",
    "       'Curricular units 1st sem (approved)',\n",
    "       'Curricular units 1st sem (grade)',\n",
    "       'Curricular units 1st sem (without evaluations)',\n",
    "       'Curricular units 2nd sem (credited)',\n",
    "       'Curricular units 2nd sem (enrolled)',\n",
    "       'Curricular units 2nd sem (evaluations)',\n",
    "       'Curricular units 2nd sem (approved)',\n",
    "       'Curricular units 2nd sem (grade)',\n",
    "       'Curricular units 2nd sem (without evaluations)', 'Unemployment rate',\n",
    "       'Inflation rate', 'GDP', 'Age at enrollment']\n",
    "\n",
    "\n",
    "print(len(categorical_nominal), len(categorical_binary), len(numerical_data))\n",
    "\n",
    "len(categorical_nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[numerical_data].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos um dicionário dos dados categóricos, a partir do descritor do conjunto de dados [1] e com auxílio do Github Copilot para acelerar a transcrição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário de dados\n",
    "\n",
    "data_cat = data.copy(deep=True)\n",
    "\n",
    "data_cat['Marital status'] = data['Marital status'].map({\n",
    "    1: 'Single',\n",
    "    2: 'Married',\n",
    "    3: 'Widower',\n",
    "    4: 'Divorced',\n",
    "    5: 'Facto union',\n",
    "    6: 'Legally separated'\n",
    "})\n",
    "\n",
    "data_cat['Nacionality'] = data['Nacionality'].map({\n",
    "    1: 'Portuguese',\n",
    "    2: 'German',\n",
    "    3: 'Spanish',\n",
    "    4: 'Italian',\n",
    "    5: 'Dutch',\n",
    "    6: 'English',\n",
    "    7: 'Lithuanian',\n",
    "    8: 'Angolan',\n",
    "    9: 'Cape Verdean',\n",
    "    10: 'Guinean',\n",
    "    11: 'Mozambican',\n",
    "    12: 'Santomean',\n",
    "    13: 'Turkish',\n",
    "    14: 'Brazilian',\n",
    "    15: 'Romanian',\n",
    "    16: 'Moldova (Republic of)',\n",
    "    17: 'Mexican',\n",
    "    18: 'Ukrainian',\n",
    "    19: 'Russian',\n",
    "    20: 'Cuban',\n",
    "    21: 'Colombian'\n",
    "})\n",
    "\n",
    "data_cat['Application mode'] = data['Application mode'].map({\n",
    "    1: '1st phase—general contingent',\n",
    "    2: 'Ordinance No. 612/93',\n",
    "    3: '1st phase—special contingent (Azores Island)',\n",
    "    4: 'Holders of other higher courses',\n",
    "    5: 'Ordinance No. 854-B/99',\n",
    "    6: 'International student (bachelor)',\n",
    "    7: '1st phase—special contingent (Madeira Island)',\n",
    "    8: '2nd phase—general contingent',\n",
    "    9: '3rd phase—general contingent',\n",
    "    10: 'Ordinance No. 533-A/99, item b2) (Different Plan)',\n",
    "    11: 'Ordinance No. 533-A/99, item b3 (Other Institution)',\n",
    "    12: 'Over 23 years old',\n",
    "    13: 'Transfer',\n",
    "    14: 'Change in course',\n",
    "    15: 'Technological specialization diploma holders',\n",
    "    16: 'Change in institution/course',\n",
    "    17: 'Short cycle diploma holders',\n",
    "    18: 'Change in institution/course (International)'\n",
    "})\n",
    "\n",
    "data_cat['Course'] = data['Course'].map({\n",
    "    1: 'Biofuel Production Technologies',\n",
    "    2: 'Animation and Multimedia Design',\n",
    "    3: 'Social Service (evening attendance)',\n",
    "    4: 'Agronomy',\n",
    "    5: 'Communication Design',\n",
    "    6: 'Veterinary Nursing',\n",
    "    7: 'Informatics Engineering',\n",
    "    8: 'Equiniculture',\n",
    "    9: 'Management',\n",
    "    10: 'Social Service',\n",
    "    11: 'Tourism',\n",
    "    12: 'Nursing',\n",
    "    13: 'Oral Hygiene',\n",
    "    14: 'Advertising and Marketing Management',\n",
    "    15: 'Journalism and Communication',\n",
    "    16: 'Basic Education',\n",
    "    17: 'Management (evening attendance)'\n",
    "})\n",
    "\n",
    "data_cat['Previous qualification'] = data['Previous qualification'].map({\n",
    "    1: 'Secondary education',\n",
    "    2: 'Higher education—bachelor’s degree',\n",
    "    3: 'Higher education—degree',\n",
    "    4: 'Higher education—master’s degree',\n",
    "    5: 'Higher education—doctorate',\n",
    "    6: 'Frequency of higher education',\n",
    "    7: '12th year of schooling—not completed',\n",
    "    8: '11th year of schooling—not completed',\n",
    "    9: 'Other—11th year of schooling',\n",
    "    10: '10th year of schooling',\n",
    "    11: '10th year of schooling—not completed',\n",
    "    12: 'Basic education 3rd cycle (9th/10th/11th year) or equivalent',\n",
    "    13: 'Basic education 2nd cycle (6th/7th/8th year) or equivalent',\n",
    "    14: 'Technological specialization course',\n",
    "    15: 'Higher education—degree (1st cycle)',\n",
    "    16: 'Professional higher technical course',\n",
    "    17: 'Higher education—master’s degree (2nd cycle)'\n",
    "})\n",
    "\n",
    "parents_qualification_mapping = {\n",
    "    1: 'Secondary Education—12th Year of Schooling or Equivalent',\n",
    "    2: 'Higher Education—bachelor’s degree',\n",
    "    3: 'Higher Education—degree',\n",
    "    4: 'Higher Education—master’s degree',\n",
    "    5: 'Higher Education—doctorate',\n",
    "    6: 'Frequency of Higher Education',\n",
    "    7: '12th Year of Schooling—not completed',\n",
    "    8: '11th Year of Schooling—not completed',\n",
    "    9: '7th Year (Old)',\n",
    "    10: 'Other—11th Year of Schooling',\n",
    "    11: '2nd year complementary high school course',\n",
    "    12: '10th Year of Schooling',\n",
    "    13: 'General commerce course',\n",
    "    14: 'Basic Education 3rd Cycle (9th/10th/11th Year) or Equivalent',\n",
    "    15: 'Complementary High School Course',\n",
    "    16: 'Technical-professional course',\n",
    "    17: 'Complementary High School Course—not concluded',\n",
    "    18: '7th year of schooling',\n",
    "    19: '2nd cycle of the general high school course',\n",
    "    20: '9th Year of Schooling—not completed',\n",
    "    21: '8th year of schooling',\n",
    "    22: 'General Course of Administration and Commerce',\n",
    "    23: 'Supplementary Accounting and Administration',\n",
    "    24: 'Unknown',\n",
    "    25: 'Cannot read or write',\n",
    "    26: 'Can read without having a 4th year of schooling',\n",
    "    27: 'Basic education 1st cycle (4th/5th year) or equivalent',\n",
    "    28: 'Basic Education 2nd Cycle (6th/7th/8th Year) or equivalent',\n",
    "    29: 'Technological specialization course',\n",
    "    30: 'Higher education—degree (1st cycle)',\n",
    "    31: 'Specialized higher studies course',\n",
    "    32: 'Professional higher technical course',\n",
    "    33: 'Higher Education—master’s degree (2nd cycle)',\n",
    "    34: 'Higher Education—doctorate (3rd cycle)'\n",
    "}\n",
    "\n",
    "data_cat[\"Mother's qualification\"] = data[\"Mother's qualification\"].map(parents_qualification_mapping)\n",
    "data_cat[\"Father's qualification\"] = data[\"Father's qualification\"].map(parents_qualification_mapping)\n",
    "\n",
    "parents_occupation_mapping = {\n",
    "    1: 'Student',\n",
    "    2: 'Representatives of the Legislative Power and Executive Bodies, Directors, Directors and Executive Managers',\n",
    "    3: 'Specialists in Intellectual and Scientific Activities',\n",
    "    4: 'Intermediate Level Technicians and Professions',\n",
    "    5: 'Administrative staff',\n",
    "    6: 'Personal Services, Security and Safety Workers, and Sellers',\n",
    "    7: 'Farmers and Skilled Workers in Agriculture, Fisheries, and Forestry',\n",
    "    8: 'Skilled Workers in Industry, Construction, and Craftsmen',\n",
    "    9: 'Installation and Machine Operators and Assembly Workers',\n",
    "    10: 'Unskilled Workers',\n",
    "    11: 'Armed Forces Professions',\n",
    "    12: 'Other Situation',\n",
    "    13: '(blank)',\n",
    "    14: 'Armed Forces Officers',\n",
    "    15: 'Armed Forces Sergeants',\n",
    "    16: 'Other Armed Forces personnel',\n",
    "    17: 'Directors of administrative and commercial services',\n",
    "    18: 'Hotel, catering, trade, and other services directors',\n",
    "    19: 'Specialists in the physical sciences, mathematics, engineering, and related techniques',\n",
    "    20: 'Health professionals',\n",
    "    21: 'Teachers',\n",
    "    22: 'Specialists in finance, accounting, administrative organization, and public and commercial relations',\n",
    "    23: 'Intermediate level science and engineering technicians and professions',\n",
    "    24: 'Technicians and professionals of intermediate level of health',\n",
    "    25: 'Intermediate level technicians from legal, social, sports, cultural, and similar services',\n",
    "    26: 'Information and communication technology technicians',\n",
    "    27: 'Office workers, secretaries in general, and data processing operators',\n",
    "    28: 'Data, accounting, statistical, financial services, and registry-related operators',\n",
    "    29: 'Other administrative support staff',\n",
    "    30: 'Personal service workers',\n",
    "    31: 'Sellers',\n",
    "    32: 'Personal care workers and the like',\n",
    "    33: 'Protection and security services personnel',\n",
    "    34: 'Market-oriented farmers and skilled agricultural and animal production workers',\n",
    "    35: 'Farmers, livestock keepers, fishermen, hunters and gatherers, and subsistence',\n",
    "    36: 'Skilled construction workers and the like, except electricians',\n",
    "    37: 'Skilled workers in metallurgy, metalworking, and similar',\n",
    "    38: 'Skilled workers in electricity and electronics',\n",
    "    39: 'Workers in food processing, woodworking, and clothing and other industries and crafts',\n",
    "    40: 'Fixed plant and machine operators',\n",
    "    41: 'Assembly workers',\n",
    "    42: 'Vehicle drivers and mobile equipment operators',\n",
    "    43: 'Unskilled workers in agriculture, animal production, and fisheries and forestry',\n",
    "    44: 'Unskilled workers in extractive industry, construction, manufacturing, and transport',\n",
    "    45: 'Meal preparation assistants',\n",
    "    46: 'Street vendors (except food) and street service providers'\n",
    "}\n",
    "\n",
    "data_cat[\"Mother's occupation\"] = data[\"Mother's occupation\"].map(parents_occupation_mapping)\n",
    "data_cat[\"Father's occupation\"] = data[\"Father's occupation\"].map(parents_occupation_mapping)\n",
    "\n",
    "data_cat['Gender'] = data['Gender'].map({\n",
    "    1: 'male',\n",
    "    0: 'female'\n",
    "})\n",
    "\n",
    "data_cat['Daytime/evening attendance'] = data['Daytime/evening attendance'].map({\n",
    "    1: 'daytime',\n",
    "    0: 'evening'\n",
    "})\n",
    "\n",
    "binary_mapping = {\n",
    "    'Displaced': {1: 'yes', 0: 'no'},\n",
    "    'Educational special needs': {1: 'yes', 0: 'no'},\n",
    "    'Debtor': {1: 'yes', 0: 'no'},\n",
    "    'Tuition fees up to date': {1: 'yes', 0: 'no'},\n",
    "    'Scholarship holder': {1: 'yes', 0: 'no'},\n",
    "    'International': {1: 'yes', 0: 'no'}\n",
    "}\n",
    "\n",
    "for column, mapping in binary_mapping.items():\n",
    "    data_cat[f'{column}'] = data[column].map(mapping)\n",
    "\n",
    "data_cat['Target'] = data['Target'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quantidade de atributos categóricos e numéricos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar a quantidade de atributos categóricos e numéricos\n",
    "num_categorical = len(data_cat.select_dtypes(include=['object']).columns)\n",
    "num_numerical = len(data_cat.select_dtypes(include=['number']).columns)\n",
    "\n",
    "print(f\"Quantidade de atributos categóricos: {num_categorical}\")\n",
    "print(f\"Quantidade de atributos numéricos: {num_numerical}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2. Qual a distribuição do atributo alvo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"Target\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Target'].describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentual de frequência das classes do atributo alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = data['Target'].value_counts(normalize=True)\n",
    "print(series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 3))\n",
    "\n",
    "sns.countplot(x = data['Target'], data = data, hue='Target', legend=False, palette='Set1',\n",
    "                order=data['Target'].value_counts().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe um **desbalanceamento nas classes do atributo alvo**. A classe 'Graduate', que representa os estudantes formados, tem 31,9% mais instâncias do que 'Enrolled', que representa os estudantes com o curso em andamento.\n",
    "\n",
    "**Possibilidade de ação**: escolher um método de amostragem para balancear as classes do atributo alvo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P3. Quais os padrões e anomalias dos atributos individuais?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributos numéricos - univariados\n",
    "\n",
    "Gráficos\n",
    "- Histograma: distribuição de frequência\n",
    "- Boxplot\n",
    "\n",
    "Estatísticas descritivas univariadas\n",
    "- Média (sensível a outliers)\n",
    "- Mediana (menos sensível a outliers)\n",
    "- Desvio padrão\n",
    "- Mínimo e máximo\n",
    "- Intervalo\n",
    "- Quartil (Q1, Q2, Intervalo Interquartil, Limites Superior e Inferior)\n",
    "- Assimetria\n",
    "- Curtose\n",
    "- Dados vazios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_data:\n",
    "    \n",
    "    # Atributo\n",
    "    print(col, end=\"\\n\\n\")\n",
    "\n",
    "    # Estatísticas descritivas\n",
    "    print('Média :', round(data[col].mean(), 2))\n",
    "    print('Mediana :', round(data[col].median(), 2))\n",
    "    print('Variância :', round(data[col].var(), 2))\n",
    "    print('Desvio padrão :', round(data[col].std(), 2))\n",
    "    print('Min :', round(data[col].min(), 2))\n",
    "    print('Max :', round(data[col].max(), 2))\n",
    "    print('Intervalo: ', round(data[col].max() - data[col].min(), 2))\n",
    "    print('Amostras únicas :', data[col].nunique())\n",
    "    print('Amostras faltando :', data[col].isnull().sum())\n",
    "    print('Q1 :', round(data[col].quantile(0.25), 2))\n",
    "    print('Q3 :', round(data[col].quantile(0.75), 2))\n",
    "    print('IQR :', round(data[col].quantile(0.75) - data[col].quantile(0.25), 2))\n",
    "    print('Limite inferior :', round(data[col].quantile(0.25) - 1.5 * (data[col].quantile(0.75) - data[col].quantile(0.25)), 2))\n",
    "    print('Limite superior :', round(data[col].quantile(0.75) + 1.5 * (data[col].quantile(0.75) - data[col].quantile(0.25)), 2))\n",
    "    print('Obliquidade :', round(data[col].skew(), 2))\n",
    "    print('Curtose :', round(data[col].kurt(), 2))\n",
    "\n",
    "    # Gráficos - referência: https://www.analyticsvidhya.com/blog/2022/07/step-by-step-exploratory-data-analysis-eda-using-python/\n",
    "    plt.figure(figsize = (20, 3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    # data[col].hist(grid=False)\n",
    "    sns.histplot(data=data, x=col, hue='Target', kde=False, palette='Set1')\n",
    "    plt.ylabel('count')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=data[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributos categóricos\n",
    "Gráficos:\n",
    "- Histograma: distribuição de frequência (contagem das classes)\n",
    "\n",
    "Estatística descritiva:\n",
    "- Moda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Distribuição de frequência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referência: https://www.analyticsvidhya.com/blog/2022/07/step-by-step-exploratory-data-analysis-eda-using-python/\n",
    "\n",
    "for col in categorical_data:\n",
    "    \n",
    "    # Atributo\n",
    "    print(col, end=\"\\n\\n\")\n",
    "\n",
    "    # Estatísticas descritivas\n",
    "    print('Moda :', round(data_cat[col].mode(), 2))\n",
    "    print('Amostras únicas :', data_cat[col].nunique())\n",
    "    print('Amostras faltando :', data_cat[col].isnull().sum())\n",
    "\n",
    "    num_labels = data_cat[col].nunique()\n",
    "\n",
    "    if num_labels > 7:\n",
    "\n",
    "        width = max(5, num_labels)\n",
    "        height = max(5, num_labels-10)\n",
    "\n",
    "        plt.figure(figsize=(width*0.8, height*1.25))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(data=data_cat, y=col, kde=False, hue='Target', palette='Set1')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylabel(col)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        plt.figure(figsize=(25, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(data=data_cat, x=col, kde=False, hue='Target', palette='Set1')\n",
    "        plt.ylabel(col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P4. Quais os padrões e anomalias entre todos os atributos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Análise bivariada** quais as relações entre pares de atributos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupando os dados por Nacionalidade e Status de Target\n",
    "stacked_data = data_cat.groupby(['Nacionality', 'Target']).size().unstack().fillna(0)\n",
    "\n",
    "# Normalizando os dados para mostrar proporções em vez de contagens absolutas\n",
    "normalized_data = stacked_data.div(stacked_data.sum(axis=1), axis=0)\n",
    "\n",
    "print(stacked_data.head())\n",
    "\n",
    "# Criando o gráfico de barras empilhadas normalizado\n",
    "normalized_data.plot(kind='barh', stacked=True, figsize=(14, 8), colormap='Pastel1')\n",
    "\n",
    "plt.title('Distribuição Proporcional por Nacionalidade e Status de Target')\n",
    "plt.xlabel('Proporção')\n",
    "plt.ylabel('Nacionalidade')\n",
    "plt.legend(title='Status de Target', loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de Distribuição de Gênero vs. Status de Target\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Gender', hue='Target', data=data_cat, palette='Set1')\n",
    "plt.title('Distribuição de Gênero vs. Status de Target')\n",
    "plt.xlabel('Gênero')\n",
    "plt.ylabel('Contagem')\n",
    "plt.legend(title='Status de Target', loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Idade\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=data_cat, x='Target', y='Age at enrollment', palette='Set1')\n",
    "plt.title('Distribuição de Idade vs. Status de Target')\n",
    "plt.xlabel('Status de Target')\n",
    "plt.ylabel('Idade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize the data for x and y\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create an empty DataFrame\n",
    "normalized_df = pd.DataFrame()\n",
    "\n",
    "normalized_df[['Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)']] = scaler.fit_transform(data[['Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)']])\n",
    "normalized_df['Target'] = data['Target']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=normalized_df, x='Curricular units 1st sem (grade)', y='Curricular units 2nd sem (grade)', hue='Target', palette='Set1')\n",
    "plt.title('Dispersão entre notas do 1º semestre e 2º semestre')\n",
    "plt.xlabel('Notas do 1º semestre')\n",
    "plt.ylabel('Notas do 2º semestre')\n",
    "plt.legend(title='Status de Target', loc='upper left')\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=data, x='Curricular units 1st sem (approved)', y='Curricular units 2nd sem (approved)', hue='Target', palette='Set1')\n",
    "plt.title('Dispersão entre aprovações do 1º semestre e 2º semestre')\n",
    "plt.xlabel('Aprovações do 1º semestre')\n",
    "plt.ylabel('Aprovações do 2º semestre')\n",
    "plt.legend(title='Status de Target', loc='upper left')\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Análise multivariada**: quais as relações entre as variáveis numéricas e categóricas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para podermos comparar variáveis numéricas e categóricas, precisamos mapear as strings categóricas para atributos numéricos. Como neste dataset, originalmente, as variáveis categóricas já estão mapeadas em valores numéricos discretos, precisamos apenas mapear o atributo alvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos mudar essas strings para valores int\n",
    "# Label encoding\n",
    "data['Target'] = data['Target'].map({\n",
    "    'Evasão':1,\n",
    "    'Permanência':0\n",
    "})\n",
    "\n",
    "print(data[\"Target\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isto, avaliamos quais fatores influenciam diretamente a desistência dos alunos através do método de correlação de Pearson. Queremos visualizar a correlação entre os atributos. Para isto, criamos uma matriz de correlação diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_corr = data.corr(method = 'pearson') # Gera uma matriz de correlação e mostra apenas as correlações entre o Target e outras variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a diagonal correlation matrix: https://seaborn.pydata.org/examples/many_pairwise_correlations.html\n",
    "def diagonal_corr_matrix(df, title):\n",
    "    sns.set_theme(style=\"white\")\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.triu(np.ones_like(df, dtype=bool))\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    diag_heatmap = sns.heatmap(df, mask=mask, cmap=cmap, vmax=.5, vmin=-.5, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "    diag_heatmap.set_title(title, fontdict={'fontsize':16}, pad=16)\n",
    "\n",
    "diagonal_corr_matrix(attribute_corr, 'Matriz de correlação diagonal entre os atributos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Existem atributos redundantes, como International e Nacionality, que têm correlação considerável entre si\n",
    "- Outras correlações significativas são óbvias, e poderiam ser úteis apenas para resumir dois atributos em um, se forem selecionados:\n",
    "  - Age at enrollment vs Marital status\n",
    "  - Age at enrollment vs Application mode\n",
    "  - Mother's occupation vs Father's occupation\n",
    "  - Mother's qualification vs Father's qualification\n",
    "  - Curricular units 1st sem vs Curricular units 2nd sem\n",
    "  - International vs Nationality\n",
    "  - Curricular units 1st sem vs Curricular units 2nd sem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pré-processamento dos dados\n",
    "\n",
    "Aplique técnicas de pré-processamento nos dados a fim de melhorar a qualidade dos mesmos por meio da eliminação ou minimização de problemas identificados na etapa anterior. A avaliação deste trabalho não exigirá um pré-processamento aprofundado, por ser um tópico ainda pouco discutido na disciplina, mas será esperado que os grupos lidem com aspectos como a remoção de atributos ou instâncias problemáticas (por exemplo, por conterem muitos valores faltantes ou não parecerem informativas para o problema), normalização de atributos, balanceamento de classes, transformação de atributos de categórico para numérico, caso se mostrem necessários nos dados escolhidos.\n",
    "\n",
    "- Remoção de atributos ou instâncias problemáticas\n",
    "- Balanceamento de classes\n",
    "- Transformação de atributos\n",
    "- Normalização de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de atributos ou instâncias problemáticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na fase de EDA, identificamos instâncias discrepantes (outliers) em alguns atributos. Porém, nenhum se trata de valores inconsistentes ou erros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a seleção de atributos, escolhemos a abordagem baseada em filtros, utilizando  a correlação de Pearson como métrica. Critérios mais avançados podem ser utilizados posteriormente, como aplicados em [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_data = data.copy(deep=True)\n",
    "\n",
    "data = data.drop(columns=[  'Age at enrollment', \"Father's occupation\", \"Father's qualification\", \"Nacionality\",\n",
    "                            \"Curricular units 1st sem (enrolled)\", \"Curricular units 1st sem (evaluations)\", \"Curricular units 1st sem (credited)\",\n",
    "                            \"Curricular units 1st sem (grade)\", \"Curricular units 1st sem (without evaluations)\",\n",
    "                            \"Curricular units 1st sem (approved)\", \"Curricular units 2nd sem (enrolled)\", \"Curricular units 2nd sem (evaluations)\", \n",
    "                            \"Curricular units 2nd sem (credited)\", \"Curricular units 2nd sem (approved)\"])\n",
    "\n",
    "attribute_corr = data.corr(method = 'pearson') # Gera uma matriz de correlação e mostra apenas as correlações entre o Target e outras variáveis\n",
    "\n",
    "diagonal_corr_matrix(attribute_corr, 'Matriz de correlação diagonal entre os atributos após remoção')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@szabo.bibor/how-to-create-a-seaborn-correlation-heatmap-in-python-834c0686b88e\n",
    "\n",
    "attr_corr_target = data.corr()[['Target']].sort_values(by='Target', ascending=False)\n",
    "\n",
    "print(attr_corr_target)\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "plt.figure(figsize=(8, 12))\n",
    "heatmap = sns.heatmap(attr_corr_target, vmin=-1, vmax=1, annot=True, cmap=cmap)\n",
    "heatmap.set_title('Atributos independentes correlacionados com o atributo alvo', fontdict={'fontsize':16}, pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classificação da correlação de Pearson pode entre diferentes autores e domínios. Podemos interpretar as correlações da seguinte maneira:\n",
    "\n",
    "Interpretação convencional: https://journals.lww.com/anesthesia-analgesia/fulltext/2018/05000/correlation_coefficients__appropriate_use_and.50.aspx\n",
    "\n",
    "| Coeficiente de correlação | Interpretação |\n",
    "|----------------------|-------------|\n",
    "| Muito forte       | 0.90 - 1.0      |\n",
    "| Forte             | 0.70 - 0.89     |\n",
    "| Moderada          | 0.40 - 0.69     |\n",
    "| Fraca             | 0.10 - 0.39     |\n",
    "| Desconsiderável   | 0.00 - 0.10     |\n",
    "\n",
    "\n",
    "**Moderadas:**\n",
    "- Tuition fees up to date                        -0.429149\n",
    "- Curricular units 1st sem (approved)            -0.479112\n",
    "- Curricular units 1st sem (grade)               -0.480669\n",
    "- Curricular units 2nd sem (approved)            -0.569500\n",
    "- Curricular units 2nd sem (grade)               -0.571792\n",
    "\n",
    "**Fracas:**\n",
    "- Age at enrollment                               0.254215\n",
    "- Debtor                                          0.229407\n",
    "- Gender                                          0.203983\n",
    "- Application mode                                0.188908\n",
    "- Displaced                                      -0.107232\n",
    "- Curricular units 1st sem (enrolled)            -0.124635\n",
    "- Curricular units 2nd sem (enrolled)            -0.141515\n",
    "- Curricular units 2nd sem (evaluations)         -0.154999\n",
    "- Scholarship holder                             -0.245354\n",
    "\n",
    "**Desprezíveis:**\n",
    "- Marital status                                  0.093712\n",
    "- Previous qualification                          0.091590\n",
    "- Curricular units 2nd sem (without evaluations)  0.079901\n",
    "- Mother's qualification                          0.059499\n",
    "- Curricular units 1st sem (without evaluations)  0.054230\n",
    "- Inflation rate                                  0.027826\n",
    "- Father's qualification                          0.016267\n",
    "- Unemployment rate                               0.012980\n",
    "- Educational special needs                       0.002806\n",
    "- Course                                         -0.000083\n",
    "- Nacionality                                    -0.001571\n",
    "- International                                  -0.010360\n",
    "- Curricular units 1st sem (credited)            -0.029308\n",
    "- Curricular units 2nd sem (credited)            -0.033038\n",
    "- GDP                                            -0.046319\n",
    "- Mother's occupation                            -0.069102\n",
    "- Application order                              -0.070485\n",
    "- Father's occupation                            -0.079753\n",
    "- Daytime/evening attendance                     -0.080499\n",
    "- Curricular units 1st sem (evaluations)         -0.090125\n",
    "\n",
    "\n",
    "Nesta análise, 20 dos 34 atributos mostraram correlação desprezível com o atributo alvo. Já os 9 atributos restantes apresentaram correlação fraca e 5 atributos correlação moderada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diverging_colors = sns.color_palette(\"RdBu\", 10)\n",
    "print(diverging_colors)\n",
    "diverging_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Define colors and bounds for symmetric intervals\n",
    "my_colors = sns.color_palette(\"RdBu\", 10)[::-1]  # Invert the palette\n",
    "my_cmap = ListedColormap(my_colors)\n",
    "bounds = [-1, -0.7, -0.4, -0.1, 0, 0.1, 0.4, 0.7, 1]\n",
    "my_norm = BoundaryNorm(bounds, ncolors=len(my_colors))\n",
    "\n",
    "attr_corr_target = data.corr()[['Target']].sort_values(by='Target', ascending=False)\n",
    "\n",
    "print(attr_corr_target)\n",
    "\n",
    "plt.figure(figsize=(8, 12))\n",
    "heatmap = sns.heatmap(attr_corr_target, vmin=-1, vmax=1, annot=True, cmap=my_cmap, norm=my_norm)\n",
    "heatmap.set_title('Atributos independentes correlacionados com o atributo alvo', fontdict={'fontsize':16}, pad=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação de atributos\n",
    "\n",
    "Com a seleção de atributos baseada em correlação com o alvo, não sobrou nenhuma coluna do tipo categórico binário para realizar transformação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[categorical_nominal].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform one-hot encoding for columns in categorical_nominal\n",
    "# data_encoded = pd.get_dummies(data, columns=categorical_nominal)\n",
    "\n",
    "# # Display the first few rows of the encoded dataframe\n",
    "# data_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://medium.com/@szabo.bibor/how-to-create-a-seaborn-correlation-heatmap-in-python-834c0686b88e\n",
    "\n",
    "# attr_corr_target = data_encoded.corr()[['Target']].sort_values(by='Target', ascending=False)\n",
    "\n",
    "# print(attr_corr_target)\n",
    "\n",
    "# plt.figure(figsize=(8, 50))\n",
    "# heatmap = sns.heatmap(attr_corr_target, vmin=-1, vmax=1, annot=True, cmap=cmap)\n",
    "# heatmap.set_title('Atributos independentes correlacionados com o atributo alvo', fontdict={'fontsize':16}, pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceamento de classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como observamos no EDA, temos um desbalanceamento entre as classes do atributo Target. Testamos técnicas de balanceamento nesta sub-seção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE da classe minoritária + Random Undersampling da classe majoritária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separa atributos preditivos e atributo alvo\n",
    "# X = data.drop('Target', axis=1)\n",
    "# y = data['Target']\n",
    "\n",
    "# print(y.value_counts())\n",
    "\n",
    "# # Realiza o SMOTE\n",
    "# # Referência https://www.geeksforgeeks.org/smote-for-imbalanced-classification-with-python/\n",
    "\n",
    "# smote = SMOTE(sampling_strategy='minority') \n",
    "# x,y = smote.fit_resample(X,y)\n",
    "\n",
    "# print(y.value_counts())\n",
    "\n",
    "# random_under = RandomUnderSampler(sampling_strategy='majority')\n",
    "# x,y = random_under.fit_resample(x,y)\n",
    "\n",
    "# print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado estranho, pois parece que o RandomUndersampling não teve efeito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(5, 3))\n",
    "\n",
    "# sns.countplot(x = y, data = x, legend=False, palette='Set1',\n",
    "#                 order=data['Target'].value_counts().index)\n",
    "\n",
    "# plt.xticks([0, 1], ['Evasão', 'Permanência'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusão: Adicionamos o SMOTE na pipeline, para evitar um vazamento de dados ao realizar o balanceamento em dados de treino e teste.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados numéricos deste dataset tem escalas bastante diferentes, como a ordem de aplicação, que é um atributo numérico ordinal, e as notas, que são atributos numéricos contínuos.\n",
    "\n",
    "Os dados foram normalizados após o split, na seção [Spot-checking](#5-spot-checking), para não acontecer contaminação nos dados de teste pelas estimativas de média e desvio padrão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_data = ['Age at enrollment',\n",
    "#  'Curricular units 1st sem (approved)',\n",
    "#  'Curricular units 1st sem (grade)',\n",
    "#  'Curricular units 2nd sem (approved)',\n",
    "#  'Curricular units 2nd sem (grade)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[numerical_data].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizaremos uma normalização por min-max scaling e padronização por z-score. Porém, como o z-score estima a média e desvio padrão de cada atributo, isto pode significar um vazamento de dados ao realizar o split de dados após este processo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Abordagem de aprendizado\n",
    "\n",
    "Defina a abordagem de aprendizado de máquina que você planeja utilizar, isto é, se o problema é de classificação ou regressão. Justifique sua escolha com base na natureza do problema e nos dados disponíveis.\n",
    "Selecione os algoritmos de aprendizado supervisionado a serem aplicados. Esta definição é de livre escolha do grupo, mas solicita-se que englobe algoritmos que constem no conteúdo programático da disciplina (podendo incluir de forma adicional outros algoritmos não abordados na disciplina).\n",
    "\n",
    "Além disso, sugere-se selecionar um conjunto diversificado de algoritmos (em termos de viés indutivo), seguindo o propósito de spot-checking. Neste trabalho prático, os algoritmos podem ser aplicados como valores padrões de hiperparâmetros ou, se for a vontade do grupo, com uma variação mínima nos mesmos (como por exemplo, uma árvore de decisão sem poda e com uma poda não muito drástica). Os grupos devem comparar ao menos 5 algoritmos distintos.\n",
    "\n",
    "Selecione as métricas de desempenho que serão usadas para avaliar os modelos a partir da definição da modelagem e da interpretação do problema a ser abordado. Neste processo, é recomendado utilizar mais de uma métrica para avaliação e comparação de modelos, mas selecionar uma métrica como critério principal de seleção de modelos (ou seja, aquela que o grupo tentará otimizar na análise de desempenho dos algoritmos). Escolha, também, a estratégia que aplicará para realizar a divisão de dados para treinamento e avaliação (holdout, cross-validation, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmos selecionados para treinamento\n",
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "dtree2 = DecisionTreeClassifier(random_state=0, max_depth=10)\n",
    "rfc_gini = RandomForestClassifier(random_state=2)\n",
    "rfc_entropy = RandomForestClassifier(random_state=2, criterion='entropy')\n",
    "lr = LogisticRegression(random_state=42)\n",
    "knn_3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "abc = AdaBoostClassifier(n_estimators=50,learning_rate=1, random_state=0, algorithm='SAMME')\n",
    "svmachine = svm.SVC(kernel='linear',probability=True)\n",
    "\n",
    "algo_dict = {'Decision Tree': dtree, 'Decision Tree Max depth 5': dtree2, 'Random Forest gini': rfc_gini, 'Random Forest entropy': rfc_entropy, 'Logistic Regression': lr, '3-Nearest Neighbors': knn_3, '5-Nearest Neighbors': knn_5, 'AdaBoost': abc, 'SVM': svmachine}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referências\n",
    "# https://machinelearningmastery.com/spot-check-machine-learning-algorithms-in-python/\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "\n",
    "def make_pipeline(model):\n",
    "    steps = list()\n",
    "\n",
    "    steps.append(('Feature Selection', SelectKBest(k=4, score_func=mutual_info_classif)))\n",
    "    steps.append(('Normalização', StandardScaler()))\n",
    "    steps.append(('Balanceamento da classe minoritária', SMOTE(sampling_strategy='minority')))\n",
    "    steps.append(('Modelo', model))\n",
    "\n",
    "    # Cria a pipeline\n",
    "    pipe = Pipeline(steps=steps)\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold\n",
    "\n",
    "X = data.drop('Target', axis=1)\n",
    "y = data['Target']\n",
    "\n",
    "# Realiza a validação cruzada repetida de um modelo, dado o número de folds e a métrica\n",
    "def evaluate_model(X, y, algorithm, name, folds, metrics, metrics_df):\n",
    "    pipeline = make_pipeline(algorithm)\n",
    "\n",
    "    # Lista de 'seeds' para garantir a reprodutibilidade das variações de random_states\n",
    "    random_states = [42, 123, 2023, 4567, 789]\n",
    "\n",
    "    # Avalia o modelo em k folds, repetindo para cada n rand_state diferente\n",
    "    for rand_state in random_states:\n",
    "        cv = KFold(n_splits=folds, random_state=rand_state, shuffle=True)\n",
    "        scores = cross_validate(pipeline, X, y, cv=cv, n_jobs=-1,\n",
    "                                scoring=metrics, return_train_score=False,\n",
    "                                return_estimator=True)\n",
    "        \n",
    "        # Organiza os resultados em um DataFrame\n",
    "        for fold in range(folds):\n",
    "            fold_scores = {'Algoritmo': name, 'Fold': fold, 'random_state': rand_state}\n",
    "            fold_scores.update({metric: scores[f'test_{metric}'][fold] for metric in metrics})\n",
    "            fold_df = pd.DataFrame(fold_scores, index=[0])\n",
    "            metrics_df = pd.concat([metrics_df, fold_df], ignore_index=True)\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Spot-checking\n",
    "\n",
    "Execute a verificação rápida dos algoritmos através do treinamento e avaliação dos modelos de acordo com as definições do item anterior. Testar uma variedade de algoritmos permite que se possa identificar quais modelos têm o melhor desempenho inicial com os dados disponíveis. Isso economiza tempo e esforço ao focar em algoritmos que realmente têm potencial.\n",
    "Recomenda-se a execução de múltiplas repetições do treinamento e avaliação usando cada algoritmo selecionado. É importante garantir a consistência dos resultados utilizando as mesmas divisões de dados em em uma determinada iteração para todos os algoritmos. Também é recomendado utilizar a definição manual de seeds em processos aleatórios (parâmetro random_state, no scikit-learn), para fins de reprodutibilidade dos experimentos. Lembre-se que neste trabalho prático não estamos interessados em realizar a otimização de hiperparâmetros ou a análise aprofundada dos modelos, como interpretabilidade dos mesmos.\n",
    "\n",
    "Faça a sumarização dos resultados da avaliação dos modelos. O objetivo desta sumarização é identificar quais algoritmos se saíram melhor e merecem seguir para uma investigação mais detalhada, fazendo uma escolha informada de algoritmos para otimização de modelos. Atenção: esta investigação está fora do escopo do T1.\n",
    "Para esta etapa, sugere-se o uso de sumarização por média e desvio padrão do desempenho, bem como gráficos do tipo box plot, violin plot, joy plot, etc, para visualização da distribuição de desempenho por modelo ao longo de n execuções. O uso de gráficos é importante pois viabiliza uma análise visual dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y, models, folds, metrics=['f1', 'precision', 'recall', 'roc_auc']):\n",
    "    metrics_df = pd.DataFrame(columns=['Algoritmo', 'Fold', 'random_state'])\n",
    "\n",
    "    # Avalia cada modelo e retorna o DataFrame atualizado\n",
    "    for name, model in models.items():\n",
    "        print(f'Avaliando o modelo {name}...')\n",
    "        metrics_df = evaluate_model(X, y, model, name, folds, metrics, metrics_df)\n",
    "        \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = evaluate_models(X, y, algo_dict, folds=10)\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, _ in algo_dict.items():\n",
    "    metrics_per_model = metrics_df[metrics_df['Algoritmo'] == name]\n",
    "\n",
    "    mean = float(round(metrics_per_model['f1'].mean(),3))\n",
    "    std = float(round(metrics_per_model['f1'].std(),3))\n",
    "    print(f'F1-Score do {name}: ', mean, f'({std})')\n",
    "\n",
    "    mean = float(round(metrics_per_model['precision'].mean(),3))\n",
    "    std = float(round(metrics_per_model['precision'].std(),3))\n",
    "    print(f'Precisão média do {name}: ', mean, f'({std})')\n",
    "\n",
    "    mean = float(round(metrics_per_model['recall'].mean(),3))\n",
    "    std = float(round(metrics_per_model['recall'].std(),3))\n",
    "    print(f'Recall média do {name}: ', mean, f'({std})')\n",
    "\n",
    "    mean = float(round(metrics_per_model['roc_auc'].mean(),3))\n",
    "    std = float(round(metrics_per_model['roc_auc'].std(),3))\n",
    "    print(f'ROC AUC média do {name}: ', mean, f'({std})')\n",
    "\n",
    "    print('\\n')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedback T1: grid com todas as métricas, dividido por painéis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_annotation(ax, xoffset, yoffset, letter):\n",
    " ax.text(xoffset, yoffset, letter, transform=ax.transAxes,\n",
    "         size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 14))\n",
    "\n",
    "# Cria 2 subfiguras para a primeira e segunda linha\n",
    "(row1fig, row2fig) = fig.subfigures(2, 1, height_ratios=[1,1])\n",
    "\n",
    "# Primeira linha\n",
    "row1_axs = row1fig.subplots(1, 2)\n",
    "row1fig.subplots_adjust(wspace=0.3, hspace=0.01, left=0, right=1.2, bottom=.3)\n",
    "\n",
    "# Segunda linha\n",
    "row2_axs = row2fig.subplots(1, 2)\n",
    "row2fig.subplots_adjust(wspace=0.3, hspace=0.01, left=0, right=1.2, bottom=.3)\n",
    "\n",
    "# F1-Score\n",
    "# ============================================================\n",
    "ax = row1_axs[0]\n",
    "ax.set_ylim(0.5, 1)\n",
    "sns.boxplot(data=metrics_df, x='Algoritmo', y='f1', hue='Algoritmo', palette='Set3', ax=ax)\n",
    "ax.tick_params(labelrotation=45)\n",
    "ax.set_title('F1-Score por Algoritmo')\n",
    "letter_annotation(ax, -.25, 1, 'a)')\n",
    "sns.despine(offset=5, trim=False, ax=ax)\n",
    "\n",
    "# Precisão\n",
    "# ============================================================\n",
    "ax = row1_axs[1]\n",
    "ax.set_ylim(0.5, 1)\n",
    "sns.boxplot(data=metrics_df, x='Algoritmo', y='precision', hue='Algoritmo', palette='Set3', ax=ax)\n",
    "ax.tick_params(labelrotation=45)\n",
    "ax.set_title('Precisão por Algoritmo')\n",
    "letter_annotation(ax, -.25, 1, 'b)')\n",
    "sns.despine(offset=5, trim=False, ax=ax)\n",
    "\n",
    "# Recall\n",
    "# ============================================================\n",
    "ax = row2_axs[0]\n",
    "ax.set_ylim(0.5, 1)\n",
    "sns.boxplot(data=metrics_df, x='Algoritmo', y='recall', hue='Algoritmo', palette='Set3', ax=ax)\n",
    "ax.tick_params(labelrotation=45)\n",
    "ax.set_title('Revocação por Algoritmo')\n",
    "letter_annotation(ax, -.25, 1, 'c)')\n",
    "sns.despine(offset=5, trim=False, ax=ax)\n",
    "\n",
    "# ROC AUC\n",
    "# ============================================================\n",
    "ax = row2_axs[1]\n",
    "ax.set_ylim(0.5, 1)\n",
    "sns.boxplot(data=metrics_df, x='Algoritmo', y='roc_auc', hue='Algoritmo', palette='Set3', ax=ax)\n",
    "ax.tick_params(labelrotation=45)\n",
    "letter_annotation(ax, -.25, 1, 'd)')\n",
    "sns.despine(offset=5, trim=False, ax=ax)\n",
    "\n",
    "# ============================================================\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente, um **gráfico comicamente grande** com todas as métricas em um mesmo plot e figura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged boxplot by metric\n",
    "metrics_long_df = metrics_df.melt(\n",
    "    id_vars=[\"Algoritmo\"],\n",
    "    value_vars=[\"f1\", \"precision\", \"recall\", \"roc_auc\"],\n",
    "    var_name=\"Métrica\",\n",
    "    value_name=\"Valor\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(data=metrics_long_df, x=\"Métrica\", y=\"Valor\", hue=\"Algoritmo\", palette=\"Set3\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Boxplot das métricas dos algoritmos agrupadas por métrica\")\n",
    "plt.legend(title=\"Algoritmo\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot for the top n\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=metrics_df, x='Algoritmo', y='f1', hue='Algoritmo', palette='Set3')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# boxplot for the top n\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=metrics_df, x='Algoritmo', y='precision', hue='Algoritmo', palette='Set3')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# boxplot for the top n\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=metrics_df, x='Algoritmo', y='recall', hue='Algoritmo', palette='Set3')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# boxplot for the top n\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=metrics_df, x='Algoritmo', y='roc_auc', hue='Algoritmo', palette='Set3')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot for the top n\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=metrics_df, x='Algoritmo', y='f1', hue='Algoritmo', palette='Set3')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# boxplot for the top n\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=metrics_df, x='Algoritmo', y='precision', hue='Algoritmo', palette='Set3')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# boxplot for the top n\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=metrics_df, x='Algoritmo', y='recall', hue='Algoritmo', palette='Set3')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# boxplot for the top n\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=metrics_df, x='Algoritmo', y='roc_auc', hue='Algoritmo', palette='Set3')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joy plot com joypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/leotac/joypy/blob/master/Joyplot.ipynb\n",
    "\n",
    "import joypy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure 'Acurácia' column is numeric\n",
    "metrics_df['f1'] = pd.to_numeric(metrics_df['f1'], errors='coerce')\n",
    "\n",
    "# Prepare the data for the joy plot\n",
    "data_for_joyplot = metrics_df.pivot(columns='Algoritmo', values='f1')\n",
    "\n",
    "plt.figure(figsize=(19, 12))\n",
    "joypy.joyplot(data_for_joyplot, colormap=plt.cm.Spectral, overlap=2, fade=True, linewidth=.5, figsize=(9,7))\n",
    "\n",
    "plt.title('Joy Plot do f1-score por algoritmo')\n",
    "plt.xlabel('F1-score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportando os dados pré-processados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para serem utilizados no notebook [t2-otimizacao.ipynb](./t2-otimizacao.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./data/clean-dataset.csv', index=False)  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Kd5SN9ttZ5a3"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
